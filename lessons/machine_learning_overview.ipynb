{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the famous wine dataset by [P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis, 2009](http://dx.doi.org/10.1016/j.dss.2009.05.016). It consists of two datasets related to red and white variants of the __*Portuguese*__ _\"Vinho Verde\"_ wine, each one with 11 attributes. tThe target is the quality of the wine based on sensory data and it is a score between 0 and 10.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = \"https://raw.githubusercontent.com/aoguedao/gmu_casbbi_data_science/main/data/winequality-red.csv\"\n",
    "# data_filepath = Path().resolve().parent / \"data\" / \"winequality-red.csv\"  # If you are running locally\n",
    "data = pd.read_csv(data_filepath, sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (data - data.min()) / (data.max() - data.min())\n",
    "sns.relplot(\n",
    "    data=normalized_data.melt(id_vars=\"quality\"),\n",
    "    kind=\"scatter\",\n",
    "    x=\"value\",\n",
    "    y=\"quality\",\n",
    "    col=\"variable\",\n",
    "    col_wrap=4,\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical problem would be to predict the quality of a new wine, either through its score or a classification as good/bad wine. \n",
    "\n",
    "__*Can we come out with a mathematical model for predicting/classifing wine without specific rules?*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we observe a quantitative response $y$ and $p$ different predictors, $ X_1, X_2, \\ldots, X_p$. We assume that there is some relationship between $Y$ and $X = (X_1, X_2,  \\ldots , X_p)$, which can be written in the very general form\n",
    "$$\n",
    "y = f(X) + \\epsilon\n",
    "$$\n",
    "Here $f$ is some fixed but unknown function of $X$, and $\\epsilon$ is a random error term, which is independent of $X$ and has mean zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, a set of inputs $X$ are readily available, but the output $y$ cannot be easily obtained. In this setting, since the error term averages to zero, we can predict $Y$ using\n",
    "$$\n",
    "\\hat{y} = \\hat{f}(X),\n",
    "$$\n",
    "where $\\hat{f}$ represents our estimate for $f$, and $\\hat{y}$ represents the resulting prediction for $Y$ . In this setting, $\\hat{f}$ is often treated as a __black-box__, in the sense\n",
    "that one is not typically concerned with the exact form of $\\hat{f}$, provided that it yields accurate predictions for $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the natural question is: _How do we estimate $f$?_\n",
    "\n",
    "In this workshop we will study several techniques and algorithms, but generally speaking, the idea is to take the observed data for a _learning_ process. These observations are called __Training Data_, because we will use these training observations to train, or teach, our method how to estimate $f$. In other words, we are looking for\n",
    "$$\n",
    "y \\approx \\hat{f}(X)\n",
    "$$\n",
    "\n",
    "Broadly speaking, most statistical learning methods for this task can be characterized as either _parametric_ or _non-parametric_. Parametric models make assumptions about the functional form or shape of $f$ in order to reduce the searching space. A typical example is Linear Regression, where we will need to estimate/fit/train only a few coefficients. On the other hand, non-parametric models do not make explicit assumptions about f, instead they seek an estimate of f that gets as close to the data points as possible. As you can imagine, the parametric models can be very interpretable and non-parametric models can be more accurate. It is important to select an adequate model depending on the trade-off between prediction and interpretability we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Complexity Interpretability](../images/complexity_interpretability.gif)\n",
    "\n",
    "[Image Source](https://ieeexplore.ieee.org/document/8844682/figures#figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most classical machine learning problems fall into one of two categories: _supervised_ or _unsupervised_. The example with the wine dataset is supervised, since we have labels for each sample. If these labels are numeric (score of wine quality) we are in a __Regression__ model; however, if labels are categories (good/bad quality), it is called a __Classification__ model.\n",
    "\n",
    "By contrast, unsupervised learning describes a more challenging situation where observations do not have any label. The situation is referred to as unsupervised because we lack a response variable that can supervise our analysis. A classical example is a __Clustering__ model, when the goal is to find relationships between samples and create groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of a model on a given data set, we need some way to measure how well its predictions actually match the observed data.\n",
    "\n",
    "Let's define the concept of __*Metric*__, as such functions can explain the performance of a model.\n",
    "\n",
    "The choice of metric completely depends on the type of model and the implementation plan of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that target values of regression models are numeric (usually continuous) values. Then we can use metrics based on normed spaces or something similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean square error corresponds to the expected value of the squared (quadratic) error. It is defined as \n",
    "\n",
    "$$\n",
    "MSE(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\hat{y}_i \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure a classification model we need different types of metrics, since we are working with categories. Before defining metrics, we will introduce a very useful tool for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm. Each row of the matrix represents the instances in an actual class, while each column represents the instances in a predicted class, or vice versa â€“ both variants are found in literature. The name stems from the fact that it makes it easy to see whether the system is confusing two classes (i.e. commonly mislabeling one as another). [- Source -](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "For a binary classification problem a confusion matrix looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![confusion_matrix](../images/confusion_matrix.png)\n",
    "\n",
    "A really useful example:\n",
    "\n",
    "![meme_cm](../images/confusion_matrix_pregnancy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, the aim is to maximize the sum of the well-classified elements, however, this depends on the problem to be solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textrm{accuracy}= \\frac{TP+TN}{TP+TN+FP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textrm{recall} = \\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textrm{precision} = \\frac{TP}{TP+FP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take for example a really bad model for the wine dataset. Consider a random predictor between the minimum and the maximum wine quaility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_model(X, target):\n",
    "    values = X[target]\n",
    "    min_target = values.min()\n",
    "    max_target = values.max()\n",
    "    return np.random.uniform(low=min_target, high=max_target, size=X.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute any metric with a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_true = data[\"quality\"]\n",
    "y_pred = random_model(data, \"quality\")\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this a good model? \n",
    "\n",
    "Answer:\n",
    "\n",
    "![cox](../images/box.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pinn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b495ef8c557e1213b070efa440d5756e52b9d742e01b39c369ce0fdb1e54097c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
